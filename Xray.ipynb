{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xray.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMf7UnBMWi4dLBVRf9mljc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MS1997/X-ray-classification/blob/master/Xray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI8lUdpRcq9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # installing kaggle library to import the data directly into Colab notebook\n",
        " ! pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIP5MRundIF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select file containing API key from local system\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziHcV-7XcndS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkR3c19jdSlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the chest x-ray data set from kaggle\n",
        "! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdIpjhc3eBWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzipping the files\n",
        "! unzip chest-xray-pneumonia.zip -d chest_xray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrNearkAjykK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting a look into the contents of the working directory\n",
        "! ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyZH7Q09iPmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing required packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import tensorflow as tf\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dropout, GlobalAveragePooling2D, Dense, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# setting all the seeds to reproduce the output for the test set \n",
        "\n",
        "SEED = 1\n",
        "import os\n",
        "import random as rn\n",
        "import numpy as np\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "rn.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJPSfC8iuWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('chest_xray/chest_xray') # we see there are train, test & validation sets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu4EvmqtmRj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting the file paths for train, test & validation sets\n",
        "train_path = 'chest_xray/chest_xray/train'\n",
        "test_path = 'chest_xray/chest_xray/test'\n",
        "val_path = 'chest_xray/chest_xray/val'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bejR3dI9-9GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets get a count of normal & pneumonia images in each of the set folders\n",
        "def get_count(given_path):\n",
        "  count_dict={'Normal':len(os.listdir(given_path + '/NORMAL')),'Pneumonia':len(os.listdir(given_path + '/PNEUMONIA'))}\n",
        "  sns.barplot(list(count_dict.keys()),list(count_dict.values()))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr30jFpKDaOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_count(train_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3DyESu_mr7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_count(test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-o3dFq1DhWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_count(val_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3zbdPwgDp77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# selecting a random normal & pneumonia chest xray from the training set\n",
        "choice_n = rn.choice(os.listdir(train_path + '/NORMAL'))\n",
        "choice_p = rn.choice(os.listdir(train_path + '/PNEUMONIA'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfFfl-WA0tc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the randomly chosen images\n",
        "norm_image = Image.open(train_path + '/NORMAL/' + choice_n)\n",
        "pne_image = Image.open(train_path + '/PNEUMONIA/' + choice_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWktF4tuwUkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the two images side by side\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(norm_image,cmap=\"gray\") # cmap=\"gray\" required to keep the images black and white \n",
        "ax2.imshow(pne_image,cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_ReHaBE80K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(img_to_array(norm_image).shape) #(1909, 1906, 1)\n",
        "print(img_to_array(pne_image).shape) #(624, 1112, 1)\n",
        "# we see that the images are of different sizes, so we need to resize these to make them same in size "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5r0tEwnzO7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to delete directories\n",
        "# import shutil\n",
        "# shutil.rmtree('chest_xray/chest_xray/augmented')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR03iK74bHb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving augmented images of the training set\n",
        "os.mkdir('chest_xray/chest_xray/augmented')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meLtEeFyFBXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image pre processing for resnet50 \n",
        "# Keeping the color_mode as rgb because we want to try pre trained models like resnet50 which require the input to have 3 channels\n",
        "# grayscale images have only one channel\n",
        "# batch_size argument of above function defaults to 32, it takes 32 images and gives back 32 randomly transfomed images, in the next epoch\n",
        "# 32 different random transformations of these images will be again taken \n",
        "# All 3 sets (including augmented images of the training) are applied with the pre processing function of resnet50 \n",
        "save_here = 'chest_xray/chest_xray/augmented'\n",
        "\n",
        "# train data generator\n",
        "train_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,height_shift_range=0.2,width_shift_range=0.2,shear_range = 0.2, horizontal_flip=True,zoom_range=0.2)\n",
        "tr_batches = train_data_generator.flow_from_directory(directory= train_path,target_size= (150,150),color_mode='rgb',batch_size = 32,seed=101,save_to_dir=save_here,save_prefix=\"new\",save_format=\"jpeg\")\n",
        "next(tr_batches)\n",
        "\n",
        "# validation data generator\n",
        "val_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "val_batches = val_data_generator.flow_from_directory(directory= val_path,target_size= (150,150),color_mode='rgb',seed=101) \n",
        "\n",
        "# test data generator\n",
        "test_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_batches = test_data_generator.flow_from_directory(directory= test_path,target_size= (150,150),color_mode='rgb',shuffle=False) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMaZ37ajix0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_aug = os.listdir('chest_xray/chest_xray/augmented')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znCw7gqxM5n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(os.listdir('chest_xray/chest_xray/augmented')) # 32 random transoformations of 32 orginal images in the training set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxmdvBIRPDNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking the shape of the augmented data\n",
        "img = load_img('chest_xray/chest_xray/augmented/'+list_aug[0])\n",
        "data = img_to_array(img)\n",
        "data.shape #(150, 150, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGlxUUgY_j8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# looking at the first 9 augmented images from train generator\n",
        "fig=plt.figure(figsize=(15, 15))\n",
        "for i in range(9):\n",
        "  img = load_img('chest_xray/chest_xray/augmented/'+list_aug[i])\n",
        "  data = img_to_array(img)\n",
        "  #define subplots\n",
        "  fig.add_subplot(330 + 1 + i)\n",
        "  plt.imshow(np.squeeze(data.astype('uint8')),cmap='gray')\n",
        "plt.show()\n",
        "# note the color change due to pre processing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtkK1CupAudP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining initial model with Transfer Learning with the resnet50 architecture\n",
        "model = keras.models.Sequential()\n",
        "base_model = ResNet50(weights= 'imagenet',include_top=False,input_shape=(150,150,3),layers=tf.keras.layers) \n",
        "#include_top=False because do not want to include the final pooling and fully connected layer of the model and own layers\n",
        "x = base_model.output # adding the resnet model\n",
        "# additional layers\n",
        "x = Dropout(0.5)(x)\n",
        "x = GlobalAveragePooling2D()(x) \n",
        "x = Dense(64)(x)\n",
        "x = Dense(2,activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "# early stopping\n",
        "callback = EarlyStopping(monitor='val_loss',patience= 2) #stop when val_loss is minimum\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cezvrLLVa1Bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_1 = model.fit_generator(tr_batches,validation_data=val_batches,epochs=10,steps_per_epoch=163,callbacks=[callback]) \n",
        "# steps_per_epoch=(3875+1341)/32, num_samples/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3uWaeqGocoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model.evaluate_generator(test_batches) #loss, accuracy =  [0.48507723212242126, 0.8237179517745972]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGPR9CMEq2Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's try training the whole model with fine tuning parameters \n",
        "base_model = ResNet50(weights='imagenet',include_top=False,input_shape=(150,150,3)) \n",
        "# include_top=False because we do not want to include the final pooling and fully connected layer of the model, we will add our own\n",
        "x = base_model.output #adding the resnet model\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False # freezing all layers except the batch normalization layers\n",
        "\n",
        "# additional layers\n",
        "x = Dropout(0.5)(x)\n",
        "x = GlobalAveragePooling2D()(x) \n",
        "x = Dense(256)(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(2,activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "#learning rate = \n",
        "lr = 0.01 #0.001 was less accuracy was 90% , 0.1 was too high\n",
        "#optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "#early stopping with custom call back\n",
        "class EarlyStoppingByLossVal(Callback):\n",
        "    def __init__(self, monitor=['val_loss'],patience=0, value=0.00001, verbose=0):\n",
        "        super(Callback, self).__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "        self.verbose = verbose\n",
        "        self.patience = patience\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # the number of epoch the model has waited when loss is below the required value\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "        if current < self.value:\n",
        "          self.wait +=1\n",
        "          if self.wait >= self.patience:\n",
        "            if self.verbose > 0:\n",
        "                print(\"Epoch %05d: early stopping\" % epoch)\n",
        "                self.model.stop_training = True\n",
        "\n",
        "callback = EarlyStoppingByLossVal(monitor='val_loss', value=0.1, verbose=1,patience=2) #stop when val_loss is less than given value\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfUmnYQoq-Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_2 = model.fit_generator(tr_batches,validation_data=val_batches,epochs=15,steps_per_epoch=163,callbacks=[callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEOZ28aCUzJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(test_batches)# [0.027545811608433723, 0.9375]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5J7EnLr0ZCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grFROM87uuSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using model.save_weights() to save the weights of the model in HDF5 format\n",
        "model.save_weights(\"/content/gdrive/My Drive/model1.h5\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqg9v06EAlr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpWQoIiYykHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/gdrive/'My Drive' # to see contents of the drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5NK_km2xiNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/content/gdrive/My Drive/model.h5') #load the previously saved weights \n",
        "# before running this the model defining block of code should be run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbrpacpLz9QE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(test_batches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N47IAMDfx0FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "probabilities = model.predict_generator(generator=test_batches,workers = 0)\n",
        "true = test_batches.classes[test_batches.index_array]\n",
        "preds = np.argmax(probabilities, axis=1)\n",
        "cm  = confusion_matrix(true, preds)\n",
        "\n",
        "ax = plt.subplot()\n",
        "sns.set(font_scale=3.0) # Adjust to fit\n",
        "sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"g\",cbar=False)\n",
        "\n",
        "label_font = {'size':'10'}  # Adjust to fit\n",
        "ax.set_xlabel('Predicted labels', fontdict=label_font)\n",
        "ax.set_ylabel('Observed labels', fontdict=label_font)\n",
        "\n",
        "title_font = {'size':'21'}  # Adjust to fit\n",
        "ax.set_title('Confusion Matrix', fontdict=title_font)\n",
        "\n",
        "ax.tick_params(axis='both', which='major', labelsize=14)  # Adjust to fit\n",
        "ax.xaxis.set_ticklabels(['Normal', 'Pneumonia'])\n",
        "ax.yaxis.set_ticklabels(['Normal', 'Pneumonia'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jkfm3EfyEPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(216+369)/624 #accuracy = 0.9375"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LloBAWs7Gsk",
        "colab_type": "text"
      },
      "source": [
        "Precision is defined as the number of true positives over the number of true positives plus the number of false positives.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8gtEhm7KGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "369/(369+18) #precision = 0.9534883720930233"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_M7rKUd7cI8",
        "colab_type": "text"
      },
      "source": [
        "Recall is defined as the number of true positives over the number of true positives plus the number of false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A2GegJU7Yak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "369/(369+21) #recall = 0.9461538461538461"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzwaNIVq05Iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-_Ycd9e2B7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting the ROC curve\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "skplt.metrics.plot_roc_curve(true, probabilities)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}